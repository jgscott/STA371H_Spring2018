sigma2 = 0.1
rho = -0.1
returns = rbvnorm(1000, mu1, mu2, sigma1, sigma2, rho)
returns
plot(returns)
rho = -0.5
# 1000 samples from this bivariate normal
returns = rbvnorm(1000, mu1, mu2, sigma1, sigma2, rho)
plot(returns)
2^20
2^22
curve(dnorm(x, 0, 1, from=-5, to=5)
)
curve(dnorm(x, 0, 1), from=-5, to=5)
curve(dt(10), from=-5, to=5, add=TRUE, col='red')
curve(dt(x,10), from=-5, to=5, add=TRUE, col='red')
curve(dnorm(x, 0, 1), from=-5, to=5)
curve(dt(x,10), from=-5, to=5, add=TRUE, col='red', lty='dotted')
curve(dnorm(x, 0, 1), from=-5, to=5)
curve(dt(x,2), from=-5, to=5, add=TRUE, col='red', lty='dotted')
curve(dnorm(x, 0, 1), from=-5, to=5)
curve(dt(x,30), from=-5, to=5, add=TRUE, col='red', lty='dotted')
library(mosaic)
data(SaratogaHouses)
# scrub the houses with 0 lot size (because, huh?)
SaratogaHouses = subset(SaratogaHouses, lotSize > 0)
lm3 = lm(price ~ livingArea + log(lotSize) + fireplaces + fuel + fireplaces:fuel, data=SaratogaHouses)
summary(lm3)
anova(lm3)
sum(perm3$r.squared > 0.5185)
# Compare p-value under F test with p value from permutation test
lm2 = lm(price ~ livingArea + log(lotSize) + fireplaces + fuel, data=SaratogaHouses)
# Shuffle the interactions but not the main effects:
perm3 = do(10000)*{
lm(price ~ livingArea + log(lotSize) + fireplaces + fuel + shuffle(fireplaces):shuffle(fuel), data=SaratogaHouses)
}
hist(perm3$r.squared, 40)
# Show critical value for alpha = 0.05 rejection region
abline(v=qdata(perm3$r.squared, p = 0.95), col='blue', lwd=2)
# Show actual test statistic
abline(v=0.5185, col='red', lwd=2)
sum(perm3$r.squared > 0.5185)
sum(perm3$r.squared > 0.5185)/10000
anova(lm3)
(perm3$r.squared - rsquared(lm2))
summary(lm3)
fstat = (perm3$r.squared - rsquared(lm2))/(1-rsquared(lm3)) * (n - 8)/(2)
fstat = (perm3$r.squared - rsquared(lm2))/(1-rsquared(lm3)) * (nrow(SaratogaHouses) - 8)/(2)
hist(fstat)
hist(fstat, prob=TRUE)
curve(df(x, 2, nrow(SaratogaHouses) - 8), add=TRUE)
hist(fstat, 50, prob=TRUE)
curve(df(x, 2, nrow(SaratogaHouses) - 8), add=TRUE)
curve(df(x, 3, nrow(SaratogaHouses) - 8), add=TRUE)
curve(df(x, 3, nrow(SaratogaHouses) - 8), add=TRUE)5
hist(fstat, 50, prob=TRUE)
curve(df(x, 3, nrow(SaratogaHouses) - 8), add=TRUE)
fstat = (perm3$r.squared - rsquared(lm2))/(1-perm3$r.squared) * (nrow(SaratogaHouses) - 8)/(2)
hist(fstat, 50, prob=TRUE)
curve(df(x, 2, nrow(SaratogaHouses) - 8), add=TRUE)
# show transformation of r2 into F statistic
fstat = (perm3$r.squared - rsquared(lm2))/(1-perm3$r.squared) * (nrow(SaratogaHouses) - 8)/(2)
hist(fstat, 50, prob=TRUE)
curve(df(x, 2, nrow(SaratogaHouses) - 8), add=TRUE)
library(mosaic)
data(SaratogaHouses)
# scrub the houses with 0 lot size (because, huh?)
SaratogaHouses = subset(SaratogaHouses, lotSize > 0)
lm3 = lm(price ~ livingArea + log(lotSize) + fireplaces + fuel + fireplaces:fuel, data=SaratogaHouses)
summary(lm3)
coef(lm3)
summary(lm3)
confint(lm3)
confint(lm3, 0.8)
confint(lm3, level=0.8)
hist(resid(lm3))
hist(resid(lm3), 50)
summary(lm3)
5960.447/3968.939
lm3 = lm(price ~ livingArea + log(lotSize) + fireplaces + fuel + fireplaces:fuel, data=SaratogaHouses)
lm2 = lm(price ~ livingArea + log(lotSize) + fireplaces + fuel, data=SaratogaHouses)
hist(perm3$r.squared, 40)
rsquared(lm3)
summary(lm3)
rsquared(lm3)
rsquared(lm2)
nrow(SaratogaHouses)
anova(lm3)
hist(resid(lm3))
hist(resid(lm3), 100)
# show transformation of r2 into F statistic
fstat = (perm3$r.squared - rsquared(lm2))/(1-perm3$r.squared) * (nrow(SaratogaHouses) - 8)/(2)
hist(fstat, 50, prob=TRUE)
?df
hist(fstat, 50, prob=TRUE)
curve(df(x, 2, nrow(SaratogaHouses) - 8), add=TRUE)
hist(fstat, 50, prob=TRUE)
curve(df(x, nrow(SaratogaHouses) - 8, 2), add=TRUE)
hist(fstat, 50, prob=TRUE)
curve(df(x, nrow(SaratogaHouses) - 8, 2), add=TRUE)
curve(4*dt(x/0.25,1),from=-5, to=5)
marketmodel = read.csv('https://jgscott.github.io/STA371H_Spring2017/data/marketmodel.csv', header=TRUE)
summary(marketmodel)
AAPL_model = lm(AAPL ~ SP500, data=marketmodel)
library(mosaic)
plot(LifeExp ~ PPGDP, data=LifeExpectancy)
# A log transformation of GDP?
hist(LifeExpectancy$PPGDP)
# Still looks nonlinear
plot(LifeExp ~ log(PPGDP), data=LifeExpectancy)
# What about stratifying by group?
xyplot(LifeExp ~ log(PPGDP) | Group, data=LifeExpectancy)
library(readr)
LifeExpectancy <- read.csv("~/Sites/STA371H_Spring2017/data/LifeExpectancy.csv")
View(LifeExpectancy)
# Still looks nonlinear
plot(LifeExp ~ log(PPGDP), data=LifeExpectancy)
# What about stratifying by group?
xyplot(LifeExp ~ log(PPGDP) | Group, data=LifeExpectancy)
# Use a model with dummy variables
lm1 = lm(LifeExp ~ log(PPGDP) + Group, data=LifeExpectancy)
plot(LifeExp ~ log(PPGDP), data=LifeExpectancy)
points(fitted(lm1) ~ log(PPGDP), data=LifeExpectancy,
col='blue', pch=19)
plotModel(lm1)
# On the transformed scale
plot(LifeExp ~ log(PPGDP), data=LifeExpectancy)
points(fitted(lm1) ~ log(PPGDP), data=LifeExpectancy,
col='blue', pch=19)
new_data = data.frame(PPGDP = 20000, group ='oecd')
predict(lm1, new_data)
predict(lm1, new_data, interval='prediction', level = 0.95)
new_data = data.frame(PPGDP = 20000, Group ='oecd')
predict(lm1, new_data, interval='prediction', level = 0.95)
a = 3
x1 = rt(10000, a)
x1 = rt(NMC, a)
x2 = rnorm(NMC)*sqrt(1/rgamma(NMC, a/2, rate=a/2))
a = 3
NMC = 10000
x1 = rt(NMC, a)
x2 = rnorm(NMC)*sqrt(1/rgamma(NMC, a/2, rate=a/2))
a = 3
NMC = 10000
x1 = rt(NMC, a)
x2 = rnorm(NMC)*sqrt(1/rgamma(NMC, a/2, rate=a/2))
qqplot(x1, x2); abline(0,1)
a = 3
NMC = 10000
x1 = rt(NMC, a)
x2 = rnorm(NMC)*sqrt(1/rgamma(NMC, a/2, rate=a/2))
qqplot(x1, x2); abline(0,1)
a = 3
NMC = 10000
x1 = rt(NMC, a)
x2 = rnorm(NMC)*sqrt(1/rgamma(NMC, a/2, rate=a/2))
qqplot(x1, x2); abline(0,1)
a = 3
NMC = 10000
x1 = rt(NMC, a)
x2 = rnorm(NMC)*sqrt(1/rgamma(NMC, a/2, rate=a/2))
qqplot(x1, x2); abline(0,1)
hist(x, 50, prob=TRUE)
a = 3
NMC = 10000
x = rnorm(NMC)*sqrt(1/rgamma(NMC, a/2, rate=a/2))
hist(x, 50, prob=TRUE)
hist(abs(x), 50, prob=TRUE)
a = 3
NMC = 10000
x = rnorm(NMC)*sqrt(1/rgamma(NMC, a/2, rate=a/2))
hist(abs(x), 50, prob=TRUE, xlim=c(0,5))
hist(abs(x), 500, prob=TRUE, xlim=c(0,5))
curve(2*dt(x, a), add=TRUE)
# Using the redundant parameterization
x = rnorm(NMC, 0, 1)*sqrt(1/rgamma(NMC, a/2, rate=a/2))
hist(abs(x), 500, prob=TRUE, xlim=c(0,5))
curve(2*dt(x, a), add=TRUE)
tau = rnorm(NMC, 0, 1)*sqrt(1/rgamma(NMC, a/2, rate=a/2))
hist(abs(tau), 500, prob=TRUE, xlim=c(0,5))
curve(2*dt(x, a), add=TRUE)
tau = rnorm(NMC, 1, 1)*sqrt(1/rgamma(NMC, a/2, rate=a/2))
hist(abs(tau), 500, prob=TRUE, xlim=c(0,5))
tau = rnorm(NMC, 3, 1)*sqrt(1/rgamma(NMC, a/2, rate=a/2))
hist(abs(tau), 500, prob=TRUE, xlim=c(0,5))
0.096*9900
9900-950
9900-990
80/(80+990)
300*250
80/1070
2500/120
library(mosaic)
library(fImport) # need to install this the first time you use it
# Import helper function
# Put this line at the top of any script where you need to simulate
# from past returns using bootstrapping.
source("http://jgscott.github.io/teaching/r/mvnorm/computereturns.R")
# Download data for a few stocks
mystocks = c("ORCL", "JNJ", "WMT", "XOM", "MRK")
myprices = yahooSeries(mystocks, from='2007-04-16', to='2017-04-25', frequency = 'daily')
head(myprices)
myreturns = computereturns(myprices)
head(myreturns)
# These don't look normal
ind = 3
hist(myreturns[,ind], 100, prob=TRUE)
curve(dnorm(x, mean(myreturns[,ind]), sd(myreturns[,ind])), add=TRUE)
totalwealth = 10000
qqnorm(myreturns[,ind])
ind = 3
hist(myreturns[,ind], 100, prob=TRUE)
curve(dnorm(x, mean(myreturns[,ind]), sd(myreturns[,ind])), add=TRUE)
hist(myreturns[,ind], 50, prob=TRUE)
curve(dnorm(x, mean(myreturns[,ind]), sd(myreturns[,ind])), add=TRUE)
totalwealth = 10000
pweights = c(0.2, 0.2, 0.2, 0.2, 0.2)
holdings = pweights * totalwealth
holdings
myreturns
dim(myreturns)
return.today = resample(myreturns, 1, orig.ids=FALSE)
return.today
holdings = holdings*(1+return.today)
holdings
totalwealth = sum(holdings)
totalwealth
setwd("~/Sites/STA371H_Spring2017/rscripts")
library(mosaic)
brca = read.csv('../data/brca.csv')
# An ordinary multiple regression model
lm1 = lm(recall ~ radiologist + symptoms, data=brca)
summary(lm1)
brca_pred = read.csv('../data/brca_pred.csv')
# now the cancer model
glm2 = glm(cancer ~ symptoms, data=brca, family='binomial')
summary(glm2)
glm3 = glm(cancer ~ recall + symptoms, data=brca, family='binomial')
library(mosaic)#
library(MatchIt)#
#
green = read.csv("../data/green.csv", header=TRUE)
# Define revenue per square foot measure#
green$RevPSF = green$Rent * green$leasing_rate / 100#
hist(green$RevPSF, 30)
mean(RevPSF ~ green_rating, data=green)
# But look at the confounders...#
mean(age ~ green_rating, data=green)#
mean(class_a ~ green_rating, data=green)#
mean(class_b ~ green_rating, data=green)
?matchit
mymatch = matchit(green_rating ~ age + class_a + class_b, data = green)
summary(mymatch)
summary(mymatch)
green_matched = match.data(mymatch)
green_matched
mean(RevPSF ~ green_rating, data= green_matched)
t.test(RevPSF ~ green_rating, data= green_matched)
